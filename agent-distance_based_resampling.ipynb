{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final sampled dataset size: 1000\n",
      "dist of samples per dataset: [79, 73, 79, 85, 88, 91, 71, 81, 84, 84, 102, 83]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import os\n",
    "\n",
    "original_data = pd.read_csv('../data/acs-2019-nist/national/national2019.csv')\n",
    "generated_data_files = [f for f in os.listdir('output_data') if f.endswith('.csv')]\n",
    "\n",
    "continuous_columns = ['AGEP', 'PINCP', 'DENSITY']\n",
    "\n",
    "epsilon = 0.1\n",
    "sensitivity = 1.0 # TODO: adjust, altho i think fine\n",
    "\n",
    "generated_datasets = [(file, pd.read_csv(f'output_data/{file}')) for file in generated_data_files]\n",
    "\n",
    "def jensen_shannon_distance(original_series, generated_series):\n",
    "    # bounded between 0 and 1\n",
    "    original_counts = original_series.value_counts(normalize=True)\n",
    "    generated_counts = generated_series.value_counts(normalize=True)\n",
    "    \n",
    "    original_counts, generated_counts = original_counts.align(generated_counts, fill_value=0)\n",
    "    \n",
    "    return jensenshannon(original_counts, generated_counts)\n",
    "\n",
    "def calculate_total_distance(original_df, generated_df):\n",
    "    total_distance = 0\n",
    "    for col in generated_df.columns: \n",
    "        total_distance += jensen_shannon_distance(original_df[col], generated_df[col])\n",
    "    return total_distance\n",
    "\n",
    "min_noisy_distance = 1e-6 \n",
    "distances = []\n",
    "for file, gen_data in generated_datasets:\n",
    "    try:\n",
    "        true_distance = calculate_total_distance(original_data, gen_data)\n",
    "        noisy_distance = true_distance # + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "        \n",
    "        noisy_distance = max(noisy_distance, min_noisy_distance)\n",
    "        distances.append((file, gen_data, noisy_distance))\n",
    "    except ValueError as e:\n",
    "        print(f\"skip {file} due to error: {e}\")\n",
    "\n",
    "weights = np.array([1 / dist[2] for dist in distances])\n",
    "weights /= weights.sum()  \n",
    "\n",
    "sample_size = len(generated_datasets[0][1])\n",
    "\n",
    "sampled_data = []\n",
    "for (file, gen_data, _), weight in zip(distances, weights):\n",
    "    num_samples = int(round(weight * sample_size))\n",
    "    sampled_data.append(gen_data.sample(n=num_samples, replace=True))\n",
    "\n",
    "final_sampled_dataset = pd.concat(sampled_data, ignore_index=True)\n",
    "\n",
    "print(\"final sampled dataset size:\", len(final_sampled_dataset))\n",
    "print(\"dist of samples per dataset:\", [len(data) for data in sampled_data])\n",
    "\n",
    "# it seems to basically be uniform most of the time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store final_sampled_dataset\n",
    "final_sampled_dataset.to_csv('final_sampled_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
